---
title: "Day 4 - How much are we Learning?"
#author: "JP"
#date: "January 22, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We look beyond each argumentâ€™s own claims to critique the generalizability of the findings, the sensitivity of the findings to the research design, the match between theory and evidence, and support for specific causal mechanisms. We also discuss publication bias, 'p-hacking' and pre-registration.

## Morning

1. [Lecture Slides](https://jonnyphillips.github.io/Causal_Critiques_2020/Day 4/Slides_Day_4_2024_v1.pdf)
2. [Exercises in Generalizability](https://jonnyphillips.github.io/Causal_Critiques_2020/Day 4/Exercises_on_Generalizability.html)
3. [Exercise on Policy Interpretation](https://jonnyphillips.github.io/Causal_Critiques_2020/Day 4/Exercises_Policy.html)

*Readings:*

- Cartwright, Nancy (2007), Are RCTs the Gold Standard?, BioSocieties, 2, 11-20
- Angus S Deaton. Instruments of Development, Randomization in the Tropics and the Search for the Elusive Keys to Economic Development. 2009.
- Steven D Levitt and John A List. What Do Laboratory Experiments Tell Us About the Real World? 2006.
- Hainmueller, Jens et al (2014), "Validating vignette and conjoint survey experiments against real-world behavior", Proceedings of the National Academy of Sciences, 112:8
- Dunning, Thad (2012), Natural Experiments in the Social Sciences: A Design-Based Approach, Ch. 10
- [optional] Monogan, James (2015),  "Research Preregistration in Political Science: The Case, Counterarguments, and a Response to Critiques"
- [optional] Jasjeet S Sekhon and Rocio Titiunik. When Natural Experiments Are Neither Natural nor Experiments. American Political Science Review, 106(1):35-57, 2012.


## Afternoon - Critiquing the Data

How much do we learn from the regression discontinuity results estimated in Day 3? First, we will implement some robustness checks:

1. Our regression discontinuity assumed a *linear* relationship between winning margin and subsequent electoral performance. Implement an alternative regression discontinuity with a more flexible quadratic relationship. How do the results differ?

2. What about a cubic relationship?

3. An alternative way to implement the regression discontinuity is to limit the data to only those units 'close' to the discontinuity. Remove any data that is more than +/-5\% from the threshold and run your (linear) regression discontinuity again. How do the results change?

4. Estimating the uncertainty (standard errors) for regression discontinuities is tricky. The 'correct' way to do it has been programmed in the 'rdrobust' package. Implement the (linear) regression discontinuity in rdrobust and compare the standard errors 

What about the scope of our conclusions?

5. To assess how different units near the threshold might be, let's compare which parties are most represented near to the threshold (+/-5\%) with those that win or lose by a landslide (win or lose by more than 20\%).

6. Based on the above tests, how generalizable do you believe the findings in Titiunik 2011 to be?

We can also replicate the study with a different data sample:

7. Use the data for the [2012](https://jonnyphillips.github.io/Causal_Critiques_2020/Replication/2012 Mayoral Elections Data.csv) and [2016](https://jonnyphillips.github.io/Causal_Critiques_2020/Replication/2016 Mayoral Elections Data.csv) elections (cleaned and merged data [here](https://jonnyphillips.github.io/Causal_Critiques_2020/Replication/rdd_data_1216.csv)) to implement a new (linear) regression discontinuity. Is the relationship the same as the results you estimated for 2000-04?

