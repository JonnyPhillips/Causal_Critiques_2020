---
title: "Day 4 - How much are we Learning?"
#author: "JP"
#date: "January 22, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Morning

1. [Lecture Slides](https://jonnyphillips.github.io/Causal_Critiques/Day 4/Slides_Day_4_v1.pdf)
2. [Exercises in Generalizability](https://jonnyphillips.github.io/Causal_Critiques/Day 4/Exercises_on_Generalizability.html)

## Afternoon - Practicing Critiques

Based on [this research paper](https://jonnyphillips.github.io/Causal_Critiques/Day 4/Boas and Hidalgo airwaves.pdf), the Ministry of Communications has proposed to ban all politicians from owning radio licences. Your task is to write a report for the Ministry: Should this ban go ahead? Does the evidence from Boas and Hidalgo provide strong justification for this ban? What do we learn and what do we *not* learn from their research? You may wish to fill in the summary template first.

Later, we will begin your individual presentations of your own/assigned papers, and the rest of the class will be tasked with providing constructive critiques.

## Afternoon - Critiquing the Data

How much do we learn from the regression discontinuity results estimated in Day 3? First, we will implement some robustness checks:

1. Our regression discontinuity assumed a *linear* relationship between winning margin and subsequent electoral performance. Implement an alternative regression discontinuity with a more flexible quadratic relationship. How do the results differ?

2. What about a cubic relationship?

3. An alternative way to implement the regression discontinuity is to limit the data to only those units 'close' to the discontinuity. Remove any data that is more than +/-5\% from the threshold and run your (linear) regression discontinuity again. How do the results change?

4. Estimating the uncertainty (standard errors) for regression discontinuities is tricky. The 'correct' way to do it has been programmed in the 'rdrobust' package. Implement the (linear) regression discontinuity in rdrobust and compare the standard errors 

What about the scope of our conclusions?

5. To assess how different units near the threshold might be, let's compare which parties are most represented near to the threshold (+/-5\%) with those that win or lose by a landslide (win or lose by more than 20\%).

6. Based on the above tests, how generalizable do you believe the findings in Titiunik 2011 to be?

We can also replicate the study with a different data sample:

7. Use the data for the [2012](https://jonnyphillips.github.io/Causal_Critiques/Replication/2012 Mayoral Elections Data.csv) and [2016](https://jonnyphillips.github.io/Causal_Critiques/Replication/2016 Mayoral Elections Data.csv) elections to implement a new (linear) regression discontinuity. Is the relationship the same as the results you estimated for 2000-04?

