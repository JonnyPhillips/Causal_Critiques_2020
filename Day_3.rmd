---
title: "Day 3 - Assessing Causal Evidence"
#author: "JP"
#date: "January 22, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We review a range of causal methodology research designs, the assumptions on which they are based and their connection to specific statistical models. We practice repeatedly assessing if these assumptions have been met.

## Morning

1. [Lecture Slides](https://jonnyphillips.github.io/Causal_Critiques_2020/Day 3/Slides_Day_3_2024_v1.pdf)
2. [Exercises on Causal Methods](https://jonnyphillips.github.io/Causal_Critiques_2020/Day 3/Exercises_on_Causal_Methods.html)

*Readings:* 

- Alan S. Gerber and Donald P Green. Field Experiments: Design, Analysis and Interpretation.
W.W. Norton & Company, 2012. Ch. 1
- Dunning, Thad (2012), Natural Experiments in the Social Sciences: A Design-Based Approach, Chs. 3, 4, 8 & 9
- Brady, Henry E. (2004), Data-Set Observations versus Causal-Process Observations: The 2000 U.S. Presidential Election
- [optional] Andrew Eggers, Olle Folke, Anthony Fowler, Jens Hainmueller, Andrew B Hall, and James M Snyder (2013). On the Validity of the Regression Discontinuity Design for Estimating Electoral Effects : New Evidence from Over 40,000 Close Races.

## Afternoon - Practicing Critiques

We work in teams to critique papers' assumptions, and the evidence to support those assumptions. For each of the papers below:

(a) Identify what type of methodology/research design the author is using.
(b) List the assumptions that are required for the methodology to produce valid causal estimates in this context.
(b) Write a critique of the methodology, highlighting whether there is any evidence that the assumptions are met. 
(c) Suggest any alternative explanations which might also be consistent with the research findings.
(d) On a scale of 0-10, how much do you believe the findings of the paper?

1. Titiunik 2011
2. De La O 2013
3. Kane et al 2004
4. Carnegie and Marinov 2017

## Afternoon - Critiquing the Data

To overcome the causal problems we saw yesterday, Titiunik implements a regression discontinuity. 

1. Draw the causal diagram (DAG) which Titiunik is assuming to be true in close elections.

2. Implement the regression discontinuity using your measure of 'close elections', your indicator of incumbency status and your measure of electoral performance in 2004.

3. Interpret the findings of the regression discontinuity. How do they differ from the observational results in Day 2?

4. One assumption of our regression discontinuity is that comparing incumbents that just won and lost elections in 2000 will produce 'balance' on potential omitted variables. There are thousands of variables we could check, but let's assess balance on the size of the municipality by comparing the number of voters in 2000 within 5\% of a tied election.

5. How does the balance close to the threshold compare with the balance of winners and losers in the full dataset?

6. Check for balance within 5\% of the threshold on other characteristics of the municipalities between treated and control units using [this file from IBGE](https://jonnyphillips.github.io/Causal_Critiques_2020/Replication/Mun_data.csv). The variables are population, IDHM (Human Development Index) and PIB (GDP per capita)

7. Another assumption of regression discontinuity is that parties cannot manipulate their 'score' on the running variable. We can assess this by checking for continuity (in contrast to lumping) in the distribution of the running variable either side of the threshold, in our case winning margin in 2000. Test this assumption by implementing a McCrary density test (DCdensity in the 'rdd' library). What do the results show?
 
8. Using any qualitative knowledge you may have, do you think it is possible for parties in this context to precisely control their winning margin by one or two percentage points? 
